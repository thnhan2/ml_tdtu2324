{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c14f9896922c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.144582300Z",
     "start_time": "2023-09-11T14:00:57.116870600Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19551fa0cc654f",
   "metadata": {},
   "source": [
    "# Dataset Information\n",
    "## Dataset\n",
    "\n",
    "- The **adult** dataset of UCI is used to predict whether income exceeds \\$50K/yr based on census data.\n",
    "- Dataset link: [adult dataset](https://archive.ics.uci.edu/dataset/2/adult).\n",
    "- Code repo in GitHub: [notebook](https://gooogle.com).\n",
    "## Aim in this notebook\n",
    "- Data cleaning\n",
    "- Data Transformation\n",
    "- Data Normalization\n",
    "- Using `sklearn`: Indicates whether an individual earns more than $50,000 per year or not.\n",
    "## Student\n",
    "- name: Tran Huu Nhan\n",
    "- id: 521H0507\n",
    "- date: 11/9/2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84a7c3a46b394e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.199576600Z",
     "start_time": "2023-09-11T14:00:57.122884900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n"
     ]
    }
   ],
   "source": [
    "# Read data from file adult.data\n",
    "data = pd.read_csv('adult.data', header=None, na_values='?', skipinitialspace=True)\n",
    "\n",
    "# defined column names\n",
    "data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# print head of dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b914232",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Handling missing values\n",
    "- Dataset contains a small amount of missing values and 3 columns is not continuous values. So that using statistical methods or removing the records with missing values.\n",
    "Using mode in this case, fill missing valued with mode of each column.\n",
    "- In this example:\n",
    "    find list names column has missing data and depend on amount of values to decided next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f270c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.267543800Z",
     "start_time": "2023-09-11T14:00:57.200528500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of value missing:\n",
      "workclass         1836\n",
      "occupation        1843\n",
      "native-country     583\n",
      "dtype: int64\n",
      "\n",
      "Percent missing: \n",
      "workclass         0.056386\n",
      "occupation        0.056601\n",
      "native-country    0.017905\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# find missing data in dataset\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "missing_value = data.isnull()\n",
    "\n",
    "missing_columns = missing_value.sum()\n",
    "print(f\"Amount of value missing:\\n{missing_columns[missing_columns > 0]}\")\n",
    "\n",
    "print(f\"\\nPercent missing: \\n{missing_columns[missing_columns >0] / len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd500cc349029cb6",
   "metadata": {},
   "source": [
    "**Has 3 columns missing value:**\n",
    "|Column|Percent|\n",
    "|-------|-------|\n",
    "|workclass|        0.056386 %| \n",
    "|occupation|       0.056601 %|\n",
    "|native-country|   0.017905 %|\n",
    "\n",
    "Because percentage of value missing is small. So that, replace missing values instead remove row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06b4614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.268553700Z",
     "start_time": "2023-09-11T14:00:57.232001600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace missing values with the column's mode.\n",
    "data['workclass'].fillna(data['workclass'].mode()[0], inplace=True)\n",
    "data['occupation'].fillna(data['occupation'].mode()[0], inplace=True)\n",
    "data['native-country'].fillna(data['native-country'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc857aaf86ffad",
   "metadata": {},
   "source": [
    "## Removing irrelevant data\n",
    "For individuals who are *without-pay* and those who have *never-worked*, they are considered exceptions in the income prediction model within this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0ea5bdc949f681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.335273500Z",
     "start_time": "2023-09-11T14:00:57.263039900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32540\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with a workclass of Without-pay\n",
    "data = data[(data['workclass'] != 'Without-pay') & (data['workclass'] != 'Never-worked')]\n",
    "\n",
    "# print number of rows in dataset after remove\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22a26eaa16fe7f",
   "metadata": {},
   "source": [
    " # Data Transformation\n",
    " ## Using Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcb3ea51ea325f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.347828400Z",
     "start_time": "2023-09-11T14:00:57.298573900Z"
    }
   },
   "outputs": [],
   "source": [
    "# import library Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a dictionary to store LabelEncoder objects for each column\n",
    "encoders = {}\n",
    "\n",
    "# Iterate over the columns to perform label encoding\n",
    "for col in ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']:\n",
    "    # Create a LabelEncoder object\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Perform label encoding on the column and update the data\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    # Store the LabelEncoder object in the dictionary\n",
    "    encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df775749b75cba8",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "## Using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89dd5c6b3306be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.399453900Z",
     "start_time": "2023-09-11T14:00:57.340828800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
      "0  0.030691          5 -1.063518          9       1.134330               4   \n",
      "1  0.837492          4 -1.008618          9       1.134330               2   \n",
      "2 -0.042655          2  0.245070         11      -0.420444               0   \n",
      "3  1.057529          2  0.425779          1      -1.197830               2   \n",
      "4 -0.776111          2  1.408077          9       1.134330               2   \n",
      "\n",
      "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
      "0           0             1     4    1      0.148341     -0.216733   \n",
      "1           3             0     4    1     -0.145941     -0.216733   \n",
      "2           5             1     4    1     -0.145941     -0.216733   \n",
      "3           5             0     2    1     -0.145941     -0.216733   \n",
      "4           9             5     2    0     -0.145941     -0.216733   \n",
      "\n",
      "   hours-per-week  native-country  income  \n",
      "0       -0.035922              38       0  \n",
      "1       -2.223516              38       0  \n",
      "2       -0.035922              38       0  \n",
      "3       -0.035922              38       0  \n",
      "4       -0.035922               4       0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# select the variables to normalize\n",
    "variables_to_normalize = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Create a scaler object to perform StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the data and compute the normalization parameters\n",
    "scaled_data = scaler.fit_transform(data[variables_to_normalize])\n",
    "\n",
    "# Update the original data with the normalized values\n",
    "data[variables_to_normalize] = scaled_data\n",
    "\n",
    "# Print a few rows of data after normalization\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcf7311d39dba89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.411761100Z",
     "start_time": "2023-09-11T14:00:57.373524900Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary library to train model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37eb2942966293c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T14:00:57.621251800Z",
     "start_time": "2023-09-11T14:00:57.389850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8246773202212662\n",
      "First 10 predictions:\n",
      "['<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '>50K' '<=50K'\n",
      " '<=50K']\n",
      "Actual values for the first 10 instances:\n",
      "['>50K' '>50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K' '<=50K'\n",
      " '<=50K']\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the machine learning model\n",
    "model = LogisticRegression(max_iter=1000) # Increase the maximum number of iterations to avoid convergence warning\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict income on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Print the first 10 predictions\n",
    "print(\"First 10 predictions:\")\n",
    "print(le.inverse_transform(y_pred[:10]))\n",
    "\n",
    "# Print the actual values for comparison\n",
    "print(\"Actual values for the first 10 instances:\")\n",
    "print(le.inverse_transform(y_test[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
